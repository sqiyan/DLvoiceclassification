{"cells":[{"cell_type":"markdown","metadata":{"id":"PrqRK8C8Sz-m"},"source":["# Run this to use google drive as data source\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26167,"status":"ok","timestamp":1650714530409,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"-Z2URWqX8Wd6","outputId":"adf18539-ceb2-4a37-87f4-74f1e1f3e36f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# not ideal but can use this if you want to get some quick work done\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import time\n","from pathlib import Path\n","\n","kf_path = \"/content/drive/MyDrive/School/SUTD Term 6/Deep Learning/Deep Learning\"\n","jk_path = \"/content/drive/MyDrive/2. SUTD/SUTD Term 7/50.039 Deep Learning/Deep Learning Project/Mozilla Audio Dataset\"\n","qy_path = \"\"\n","riley_path = \"\"\n","se_path = \"\"\n","\n","# Change this your path to the gdrive\n","pwd = jk_path\n","model_ckpt_folder = \"JunKai_Models\"\n","\n","csv_file_path = Path(pwd, \"formatted.csv\")\n","root_audio_dir = Path(pwd, \"root_audio_dir/\")\n","audio_zip_path = Path(pwd, \"root_audio_dir.zip\")"]},{"cell_type":"markdown","metadata":{"id":"1JU1BVteunfP"},"source":["Takes up to 38GB available left\n","After running drops down to 50.86GB available left"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fB6aTROKptyK"},"outputs":[],"source":["!unzip -n -q \"$audio_zip_path\" -d ./\n","\n","root_audio_dir = \"root_audio_dir/\""]},{"cell_type":"markdown","metadata":{"id":"n7vNWPCDaRIs"},"source":["## OR Run this to use google colab as data source"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o3fawjGfOi7n"},"outputs":[],"source":["# !wget \"https://drive.google.com/uc?id=1MKzu-TfLKEygWOK5FpbVBsI8sKeB48DC&confirm=t\"\n","# !mv \"uc?id=1MKzu-TfLKEygWOK5FpbVBsI8sKeB48DC&confirm=t\" root_audio_dir.zip\n","\n","\n","# !wget \"https://drive.google.com/uc?export=download&id=1v0zhoVKLCSudS4XJFJHR3GWN28B5zdBB\"\n","# !mv \"uc?export=download&id=1v0zhoVKLCSudS4XJFJHR3GWN28B5zdBB\" formatted.csv\n","\n","\n","# csv_file_path = \"formatted.csv\"\n","# root_audio_dir = \"root_audio_dir/\""]},{"cell_type":"markdown","metadata":{"id":"faBReymMbmkO"},"source":["### Unzip and remove zip file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sq0kIKUOZU3P"},"outputs":[],"source":["# !unzip -q root_audio_dir.zip\n","# !rm root_audio_dir.zip\n","# !du -sh ./*"]},{"cell_type":"markdown","metadata":{"id":"tigPi8LPeMsX"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9854,"status":"ok","timestamp":1650714839892,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"Sp_izuI-cSp_","outputId":"8cc0243a-3bb8-4247-e612-3cc2e13a625e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.6.1-py3-none-any.whl (582 kB)\n","\u001b[?25l\r\u001b[K     |▋                               | 10 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 61 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 71 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 81 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█████                           | 92 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 102 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 112 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 122 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 133 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 143 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 153 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 163 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 174 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 184 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 194 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 204 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 215 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 225 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 235 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 245 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 256 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 266 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 276 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 286 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 296 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 307 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 317 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 327 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 337 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 348 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 358 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 368 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 378 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 389 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 399 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 409 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 419 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 430 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 440 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 450 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 460 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 471 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 481 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 491 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 501 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 512 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 522 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 532 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 542 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 552 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 563 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 573 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 582 kB 12.7 MB/s \n","\u001b[?25hCollecting torchinfo\n","  Downloading torchinfo-1.6.5-py3-none-any.whl (21 kB)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.1.1)\n","Collecting PyYAML>=5.4\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 31.0 MB/s \n","\u001b[?25hCollecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n","\u001b[K     |████████████████████████████████| 408 kB 63.6 MB/s \n","\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 69.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n","Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.10.0+cu111)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 59.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.8)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.44.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 69.8 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 56.1 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.2 MB/s \n","\u001b[?25hInstalling collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, PyYAML, torchinfo, pytorch-lightning\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.1 torchinfo-1.6.5 torchmetrics-0.8.0 yarl-1.7.2\n"]}],"source":["!pip install pytorch-lightning torchinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34rUKUc8eQ-M"},"outputs":[],"source":["import os\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchaudio\n","import torchaudio.transforms as T\n","import torch.utils.data as data\n","import pytorch_lightning as pl\n","\n","from torchinfo import summary"]},{"cell_type":"markdown","metadata":{"id":"LcLe9y1pDbVc"},"source":["# Creating Dataset to be fed into DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EGiOdcck8kH0"},"outputs":[],"source":["class CommonVoicesDataset(data.Dataset):\n","    # Some definitions:\n","    #   aud = (signal, sample_rate)\n","    #   sr = sample_rate\n","\n","    label_to_index = {i_val: i_in \n","                      for i_in, i_val in enumerate([\"teens\", \"twenties\",\n","                                                    \"thirties\", \"fourties\", \n","                                                    \"fifties\", \"sixties\"])}\n","\n","    def __init__(self, annotations_file, audio_dir, sample_rate, preprocessor):\n","        # preprocessor takes in aud and returns signal\n","\n","        self.annotations = pd.read_csv(annotations_file)\n","        if len(self.annotations.columns)> 2:\n","          columns_to_remove = []\n","          for col in self.annotations.columns:\n","            if not col in ['path','age']:\n","              columns_to_remove.append(col)\n","          self.annotations = self.annotations.drop(columns_to_remove, axis=1)\n","        self.audio_dir = audio_dir\n","        self.sample_rate = sample_rate\n","        self.resamplers = {}\n","        self.preprocessor = preprocessor\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        audio_sample_path = self._get_audio_sample_path(index)\n","        label = self._get_label(index)\n","        index = CommonVoicesDataset.label_to_index[label]  # Get index instead\n","        aud = torchaudio.load(audio_sample_path)\n","\n","        # resample to 48000 if different sample rate\n","        aud = self._resample(aud)\n","\n","        # Preprocessing step here\n","        signal = self.preprocessor(aud)\n","\n","        return signal, index\n","\n","    def _get_audio_sample_path(self, index):\n","        path = self.annotations.iloc[index,0]    \n","        final = os.path.join(self.audio_dir, path)\n","        return final\n","\n","    def _resample(self, aud, new_sr=None):\n","        if new_sr is None: new_sr = self.sample_rate\n","        signal, sr = aud\n","        if sr != new_sr:\n","            if not sr in self.resamplers:\n","                # Cache of resampling functions\n","                self.resamplers[sr] = T.Resample(sr, new_sr, dtype=signal.dtype)\n","            signal = self.resamplers[sr](signal)\n","        return signal, new_sr\n","\n","    def _get_label(self, index):\n","        return self.annotations.iloc[index,1]"]},{"cell_type":"markdown","metadata":{"id":"qa5-A39G1ehk"},"source":["# Audio preprocessing & mel spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DoFuJgyMP_X4"},"outputs":[],"source":["#Output: tensor\n","import matplotlib.pyplot as plt\n","import math\n","import random\n","import torch\n","import torchaudio\n","from torchaudio import transforms\n","\n","class AudioUtil():\n","    @staticmethod\n","    def open(audio_file):\n","        #load audio file\n","        signal, sample_rate = torchaudio.load(audio_file)\n","        return signal, sample_rate\n","\n","    @staticmethod\n","    def standardize_channel(aud):\n","        #to standardize the audio files to 1 channel (in case some have 2)\n","        signal, sample_rate = aud\n","\n","        if signal.shape[0] > 1:\n","          signal = torch.mean(signal, dim=0, keepdim=True)\n","\n","        return signal, sample_rate\n","\n","    @staticmethod\n","    def resampling(aud, target_sr):\n","      signal, sample_rate = aud\n","\n","      if sample_rate == target_sr:\n","        return aud\n","\n","      else:\n","        channel = signal.shape[0]\n","        resampled = torchaudio.transforms.Resample(sample_rate, target_sr)(signal[:1,:])\n","\n","        return resampled, target_sr\n","\n","\n","    @staticmethod\n","    def standardize_duration(aud, max_time):\n","        #standardize all audio files to the same length by either extending duration with silence or truncating it\n","        signal, sample_rate = aud\n","        num_of_rows, signal_length = signal.shape\n","        max_length = sample_rate//1000 * max_time\n","\n","        if (signal_length > max_length):\n","            #truncate signal to given length\n","            signal = signal[:, :max_length]\n","\n","        elif (signal_length < max_length):\n","            #length of padding to add\n","            padding_len = max_length - signal_length\n","\n","            #pad with 0s\n","            padding = torch.zeros(num_of_rows, padding_len)\n","\n","            signal = torch.cat((signal, padding), 1)\n","\n","        return signal, sample_rate\n","\n","    @staticmethod\n","    def time_shift(aud, shift_limit):\n","        #data augmentation on raw audio by time shifting to left/right by a random amount\n","        signal, sample_rate = aud\n","        _, signal_length = signal.shape\n","        amount_to_shift = int(random.random() * shift_limit * signal_length)\n","\n","        return signal.roll(amount_to_shift), sample_rate\n","\n","    @staticmethod\n","    def spectro_gram(aud, n_mels=64, n_fft = 1024, hop_len=None):\n","        #convert augmented audio to a mel spectrogram\n","        signal, sample_rate = aud\n","        top_db = 100\n","\n","        # Resultant length is sample_rate * seconds / (n_fft//2 - 1)\n","        spec = transforms.MelSpectrogram(sample_rate, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(signal)\n","\n","        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n","        return spec\n","\n","    @staticmethod\n","    def mel_spectrogram_augment(spec, max_mask=0.1, n_freq_masks=1, n_time_masks=1):\n","        #another round of augmentation, on mel spectrogram rather than raw data\n","        #frequency mask and time mask\n","        _, n_mels, n_steps = spec.shape\n","        mask_value = spec.mean()\n","        aug_spec = spec\n","\n","        #freq_mask_param: max possible time of the mask\n","        freq_mask_param = max_mask * n_mels\n","        for _ in range (n_freq_masks):\n","            aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n","\n","        #time_mask_param: max possible time of the mask\n","        time_mask_param = max_mask * n_steps\n","        for _ in range (n_time_masks):\n","            aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n","\n","        return aug_spec\n","\n","def example_spec_from_aud(audio_path):\n","    # Sample preprocessing pipeline\n","    aud = AudioUtil.open(audio_path)\n","    #reaud = AudioUtil.resampling(aud, 8000) #change the number to the sampling rate you want, here is 8khz\n","    mono = AudioUtil.standardize_channel(aud)\n","    fixed_duration = AudioUtil.standardize_duration(mono, 5000) #duration = 5s\n","    shift_aud = AudioUtil.time_shift(fixed_duration, 0.4) #40%\n","    spectrogram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n","    #n_mels = 64 because that is the normal speaking vocal range\n","    aug_sgram = AudioUtil.mel_spectrogram_augment(spectrogram, max_mask=0.1, n_freq_masks=2, n_time_masks=2)\n","    return aug_sgram\n","\n","\n","#######################################\n","###     preprocessing functions     ###\n","#######################################\n","\n","def raw_from_aud(aud):\n","    # Takes in raw aud, outputs preprocessed raw signal\n","    # Edit this to tune preprocessing\n","    \n","    new_aud = AudioUtil.resampling(aud, 8000) #change the number to the sampling rate you want, here is 8khz\n","    signal, sr = AudioUtil.standardize_channel(new_aud)\n","    # signal, sr = AudioUtil.standardize_duration(new_aud, 5000) #duration = 5s\n","\n","    return signal\n","\n","def spec_from_aud(aud):\n","    # Takes in raw aud, outputs preprocessed mel spectrogram\n","    # Edit this to tune preprocessing\n","\n","    new_aud = AudioUtil.standardize_channel(aud)\n","    new_aud = AudioUtil.standardize_duration(new_aud, 5460) #duration = 5.46s to get mel output length of 512\n","    new_aud = AudioUtil.time_shift(new_aud, 0.4) #40%\n","    spectrogram = AudioUtil.spectro_gram(new_aud, n_mels=64, n_fft=1024, hop_len=None)\n","    #n_mels = 64 because that is the normal speaking vocal range\n","    spectrogram = AudioUtil.mel_spectrogram_augment(spectrogram, max_mask=0.1, n_freq_masks=2, n_time_masks=2)\n","\n","    return spectrogram\n","\n","def print_spectrogram(tensor_input):\n","  #time vs amplitude\n","  two_d_spec = tensor_input[0]\n","  return plt.imshow(two_d_spec.permute(0,1))\n","\n","# output1 = example_spec_from_aud(\"/content/common_voice_en_1075485.mp3\")\n","# print (output1)\n","# print_spectrogram(output1)\n","# #print (output1.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"84zXhG71Djw-"},"source":["# Viewing dataset and Obtaining Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUS8sLrcawQt"},"outputs":[],"source":["##############################\n","###  Parameters to change  ###\n","##############################\n","\n","# Put your preprocessing functions here\n","PREPROCESSOR = raw_from_aud\n","# PREPROCESSOR = spec_from_aud\n","\n","BATCH_SIZE = 1  # Default 64\n","# If we were to have variable input length, keep batch_size at 1 or implement collate_fn()\n","\n","# This cuts the dataset down to have faster iterations during prototyping\n","REDUCED_DATASET = True\n","\n","num_workers = 4\n","# Need to experiment in this parameter.\n","# Colab gives 2 CPU cores."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2066,"status":"ok","timestamp":1650714850138,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"hTw-QkV1Cg-i","outputId":"f412f48a-2bf1-4f80-ea28-336787033fad"},"outputs":[{"output_type":"stream","name":"stdout","text":["there are 450000 samples in the dataset\n","\n","the signal for the 300,000th dataset is:\n","\t tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -4.2633e-07,\n","         -1.4568e-07,  2.2841e-07]])\n","the label for the 300,000th dataset is:\n","\t 4 \n","\n","train_loader size:  45000\n","val_loader size:    4500\n","test_loader size:   9000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}],"source":["ANNOTATIONS_FILE = csv_file_path\n","AUDIO_DIRECTORY = root_audio_dir\n","SAMPLE_RATE = 48000\n","\n","cvd = CommonVoicesDataset(ANNOTATIONS_FILE, AUDIO_DIRECTORY, SAMPLE_RATE, PREPROCESSOR)\n","cvd_num_samples = len(cvd)\n","\n","print(f'there are {cvd_num_samples} samples in the dataset\\n')\n","\n","signal, label = cvd[299999]\n","print(\"the signal for the 300,000th dataset is:\\n\\t\",signal)\n","print(\"the label for the 300,000th dataset is:\\n\\t\",label,\"\\n\")\n","\n","if REDUCED_DATASET:\n","    # 10% for train_set, 1% for val, 2% for test\n","    train_set, val_set, test_set, _ = data.random_split(cvd, [int(cvd_num_samples * i) for i in (0.1, 0.01, 0.02, 0.87)])\n","else:\n","    # 80 - 20 split for train-test and then train-val\n","    train_set, val_set, test_set = data.random_split(cvd, [int(cvd_num_samples * i) for i in (0.64, 0.16, 0.20)])\n","\n","# checking if all rows are present\n","# for i in cvd:\n","#   if i == None:\n","#     print(\"error\")\n","#   pass\n","\n","train_loader = data.DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=num_workers)\n","val_loader = data.DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=num_workers)\n","test_loader = data.DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=num_workers)\n","\n","print(f\"train_loader size:  {len(train_loader.dataset)}\")\n","print(f\"val_loader size:    {len(val_loader.dataset)}\")\n","print(f\"test_loader size:   {len(test_loader.dataset)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":516,"status":"ok","timestamp":1650714850611,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"e3a3gF9FJi38","outputId":"097282b0-f82b-4661-da7c-e61064120244"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.8401e-05,\n","           1.1528e-04, -1.5315e-05]]])\n","torch.Size([1, 1, 51840])\n","\n","tensor([0])\n"]}],"source":["for a, b in train_loader:\n","    input_shape = a.shape\n","    print(a)\n","    print(input_shape)\n","    print()\n","    print(b)\n","    # print_spectrogram(a[0])\n","    # print_spectrogram(a[1])\n","    break\n","\n","# The result is batched"]},{"cell_type":"markdown","metadata":{"id":"YkmRG51QU-SG"},"source":["# Model functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57,"status":"ok","timestamp":1650714850613,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"TTeceVeLxyNz","outputId":"565da6e2-1b5c-4c84-997e-ca3737c0de3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available: True\n"]}],"source":["# Load cuda, define device for torch\n","use_cuda = True\n","print(\"CUDA is available:\", torch.cuda.is_available())\n","device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"kiOCJ6xwYAz5"},"source":["## Standard parameters\n","- Loss function\n","- Optimizer\n","- training parameters\n","\n","Edit if needed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jBAsufOAXj4E"},"outputs":[],"source":["loss_function = F.nll_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6JnU7APEVNWs"},"outputs":[],"source":["optimizer = torch.optim.Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1650714850619,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"H734oD33X1vG","outputId":"9e120022-fa6a-4abf-ea1d-82ac42d0a558"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fda1299b090>"]},"metadata":{},"execution_count":15}],"source":["# Define training parameters\n","learning_rate = 0.001\n","epochs = 50\n","torch.manual_seed(28)"]},{"cell_type":"markdown","metadata":{"id":"wlFu63MhVlfW"},"source":["## Model definition\n","\n","\n","- [x] Normalisation after pooling\n","- [ ] relu after convolution\n","- [ ] Short cut connection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8BRee32EViH6"},"outputs":[],"source":["############################\n","### Edit your model here ###\n","############################\n","\n","# Basic CNN implementation for Mels spectrogram\n","class CustomModel(nn.Module):\n","\n","    def __init__(self, num_classes=6, any_other_params_you_need=None):\n","        super().__init__()\n","        self.num_classes = num_classes\n","\n","        # Define your layers here:\n","        self.conv1_1 = nn.Conv1d(1, 8, 2, padding=\"same\")\n","        self.conv1_2 = nn.Conv1d(8, 8, 2, dilation=2, padding=\"same\")\n","        self.bn1 = nn.BatchNorm1d(8)\n","        self.conv1_3 = nn.Conv1d(8, 16, 2, dilation=4, padding=\"same\")\n","        self.conv1_4 = nn.Conv1d(16, 16, 2, dilation=8, padding=\"same\")\n","        self.bn2 = nn.BatchNorm1d(16)\n","        self.conv1_5 = nn.Conv1d(16, 32, 2, dilation=16, padding=\"same\")\n","        self.conv1_6 = nn.Conv1d(32, 32, 2, dilation=32, padding=\"same\")\n","        self.bn3 = nn.BatchNorm1d(32)\n","\n","        self.lstm1 = nn.LSTM(32, 32)\n","\n","        self.fc1 = nn.Linear(32, self.num_classes)\n","\n","        self.poolingx2 = lambda x: F.max_pool1d(x, 2, stride=2)\n","\n","    def forward(self, inputs):\n","\n","        # print(\"input\", inputs.shape)\n","\n","        x1 = self.conv1_1(inputs)\n","        x1 = self.poolingx2(x1)\n","        x1 = self.conv1_2(x1)\n","        x1 = self.poolingx2(x1)\n","        x1 = self.bn1(x1)\n","        # print(\"x1\", x1.shape)\n","\n","        x2 = self.conv1_3(x1)\n","        x2 = self.poolingx2(x2)\n","        x2 = self.conv1_4(x2)\n","        x2 = self.poolingx2(x2)\n","        x2 = self.bn2(x2)\n","\n","        # print(\"x2\", x2.shape)\n","\n","        x3 = self.conv1_5(x2)\n","        x3 = self.poolingx2(x3)\n","        x3 = self.conv1_6(x3)\n","        x3 = self.poolingx2(x3)\n","        x3 = self.bn3(x3)\n","\n","        # print(\"x3\", x3.shape)\n","\n","        x4 = torch.transpose(x3, 1, 2)\n","        x4, _ = self.lstm1(x4)\n","        x4 = x4[:,-1, :]  # Get the last output\n","\n","        # print(\"x4\", x4.shape)\n","        \n","        x5 = self.fc1(x4)\n","\n","        # print(\"x5\", x5.shape)\n","\n","        # x = torch.cat([x1, x12], dim=1)\n","\n","        return F.log_softmax(x5, dim=1)\n"]},{"cell_type":"markdown","metadata":{"id":"z83VEs0WX8BC"},"source":["# Train model"]},{"cell_type":"markdown","source":["### Initialise trainer"],"metadata":{"id":"2fPtcmLxyVhx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhGr2ZRoPo13"},"outputs":[],"source":["import pytorch_lightning as pl\n","import torchmetrics\n","\n","class LightningModel(pl.LightningModule):\n","    def __init__(self, model, learning_rate=1e-3, loss_function=F.nll_loss, optimizer=torch.optim.Adam, weight_decay=1e-6):\n","        super().__init__()\n","        self.learning_rate = learning_rate\n","        self.loss_function = loss_function\n","        # Weight decay for L2 regularization\n","        self.optimizer = optimizer(model.parameters(), lr=self.learning_rate, weight_decay=weight_decay)\n","        self.model = model\n","        \n","        self.train_acc = torchmetrics.Accuracy()\n","        self.val_acc = torchmetrics.Accuracy()\n","        self.test_acc = torchmetrics.Accuracy()\n","\n","    def forward(self, x):\n","        # in lightning, forward defines the prediction/inference actions\n","        output = self.model(x)\n","        return output\n","\n","    def training_step(self, batch, batch_idx):\n","        # training_step defined the train loop.\n","        # It is independent of forward\n","        x, y = batch\n","        output = self(x)  # Call self.forward function\n","        loss = self.loss_function(output, y)\n","        self.train_acc(output, y)\n","        # Logging to TensorBoard by default\n","        self.log(\"train_loss\", loss, on_epoch=True)\n","        self.log(\"train_acc\", self.train_acc, on_epoch=True)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        # training_step defined the train loop.\n","        # It is independent of forward\n","        x, y = batch\n","        output = self(x)  # Call self.forward function\n","        loss = self.loss_function(output, y)\n","        self.val_acc(output, y)\n","        # Logging to TensorBoard by default\n","        self.log(\"val_loss\", loss, on_epoch=True)\n","        self.log(\"val_acc\", self.val_acc, on_epoch=True)\n","        return loss\n","\n","    def test_step(self, batch, batch_idx):\n","        # training_step defined the train loop.\n","        # It is independent of forward\n","        x, y = batch\n","        output = self(x)  # Call self.forward function\n","        loss = self.loss_function(output, y)\n","        self.test_acc(output, y)\n","        # Logging to TensorBoard by default\n","        self.log(\"test_loss\", loss, on_epoch=True)\n","        self.log(\"test_acc\", self.test_acc, on_epoch=True)\n","        return loss\n","\n","    def configure_optimizers(self):\n","        return self.optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15064,"status":"ok","timestamp":1650714866112,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"AUR9A9RcM3tz","outputId":"2e327b6b-ee2e-4a1e-dd0d-9dd459856f47"},"outputs":[{"output_type":"stream","name":"stdout","text":["model will be saved at: /content/drive/MyDrive/2. SUTD/SUTD Term 7/50.039 Deep Learning/Deep Learning Project/Mozilla Audio Dataset/JunKai_Models/04-23_11-54-10\n","LightningModel(\n","  (model): CustomModel(\n","    (conv1_1): Conv1d(1, 8, kernel_size=(2,), stride=(1,), padding=same)\n","    (conv1_2): Conv1d(8, 8, kernel_size=(2,), stride=(1,), padding=same, dilation=(2,))\n","    (bn1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv1_3): Conv1d(8, 16, kernel_size=(2,), stride=(1,), padding=same, dilation=(4,))\n","    (conv1_4): Conv1d(16, 16, kernel_size=(2,), stride=(1,), padding=same, dilation=(8,))\n","    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv1_5): Conv1d(16, 32, kernel_size=(2,), stride=(1,), padding=same, dilation=(16,))\n","    (conv1_6): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=same, dilation=(32,))\n","    (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (lstm1): LSTM(32, 32)\n","    (fc1): Linear(in_features=32, out_features=6, bias=True)\n","  )\n","  (train_acc): Accuracy()\n","  (val_acc): Accuracy()\n","  (test_acc): Accuracy()\n",")\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:298: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:647.)\n","  self.padding, self.dilation, self.groups)\n"]},{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","LightningModel                           --                        --\n","├─CustomModel: 1-1                       [1, 6]                    --\n","│    └─Conv1d: 2-1                       [1, 8, 51840]             24\n","│    └─Conv1d: 2-2                       [1, 8, 25920]             136\n","│    └─BatchNorm1d: 2-3                  [1, 8, 12960]             16\n","│    └─Conv1d: 2-4                       [1, 16, 12960]            272\n","│    └─Conv1d: 2-5                       [1, 16, 6480]             528\n","│    └─BatchNorm1d: 2-6                  [1, 16, 3240]             32\n","│    └─Conv1d: 2-7                       [1, 32, 3240]             1,056\n","│    └─Conv1d: 2-8                       [1, 32, 1620]             2,080\n","│    └─BatchNorm1d: 2-9                  [1, 32, 810]              64\n","│    └─LSTM: 2-10                        [1, 810, 32]              8,448\n","│    └─Linear: 2-11                      [1, 6]                    198\n","├─Accuracy: 1-2                          --                        --\n","├─Accuracy: 1-3                          --                        --\n","├─Accuracy: 1-4                          --                        --\n","==========================================================================================\n","Total params: 12,854\n","Trainable params: 12,854\n","Non-trainable params: 0\n","Total mult-adds (M): 25.35\n","==========================================================================================\n","Input size (MB): 0.21\n","Forward/backward pass size (MB): 10.37\n","Params size (MB): 0.05\n","Estimated Total Size (MB): 10.63\n","=========================================================================================="]},"metadata":{},"execution_count":18}],"source":["############################\n","###  Specify model name  ###\n","############################\n","\n","# If there is a model with the same name, training will continue on from that model\n","model_name = \"\"\n","\n","\n","if model_name == \"\":\n","    model_name = time.strftime(\"%m-%d_%H-%M-%S\", time.gmtime())\n","    model = LightningModel(CustomModel(), learning_rate=learning_rate, loss_function=loss_function, optimizer=optimizer)\n","else:\n","    # Load state dict from the disk (make sure it is the same name as above)\n","    state_dict = torch.load(model_name)\n","\n","    # Create a new model and load the state\n","    model = LightningModel(CustomModel(), learning_rate=learning_rate, loss_function=loss_function, optimizer=optimizer)\n","    model.load_state_dict(state_dict)\n","\n","model_save_path = Path(pwd, model_ckpt_folder)\n","\n","print(\"model name\", model_name)\n","print(\"model will be saved at:\", model_save_path)\n","print(model)\n","\n","summary(model, input_size=input_shape)  # This function will throw error when model is ill-defined"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snfuCmk8enWG"},"outputs":[],"source":["from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n","\n","# https://pytorch-lightning.readthedocs.io/en/stable/common/early_stopping.html\n","earlystopping_cb = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=4)\n","\n","# https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.ModelCheckpoint.html\n","# Saves file like: <model_save_path>/<modelname>_2_0.32.ckpt\n","modelckpt_cb = ModelCheckpoint(monitor=\"val_loss\", dirpath=model_save_path, filename=model_name+\"_{epoch}_{val_loss:.2f}\")\n","\n","callbacks = [earlystopping_cb, modelckpt_cb] \n"]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"bnrWX0mVyazA"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":839},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1650716660709,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"lxa1zvQQMrPU","outputId":"d9f1a5fa-094c-495d-fbd0-c4bff9e5764d"},"outputs":[],"source":["# Launch tensorboard\n","\n","%reload_ext tensorboard\n","%tensorboard --logdir=lightning_logs/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":468,"referenced_widgets":["b839ab825d4f4579aec421db000dd1ed","be9c1e593bd34a62933c586912343573","50fd3a076ca54a46ab255798a998cad9","22a13dd545074b64b7b17c419e762c34","c57ad4825fb845d0bf5e7575e0206a05","62eaa32e58734703b2a505f8c941635e","e48d3d93b4284997b341e0dbbf7453b4","b7956156adfd4a9bb0892423117cdc37","a0452d9a90ae4bb8844b84b7d5a1c1d9","6ac39a2e44cc46d196344658170996cb","908e808c239646a0a4d492e007c0bb04","c4bbbc5064c346fda8bffd0500b5fb10","163d9da531934d3eb1f20d64d77edb29","35fdd2fe7e8b4a118d270e668f0165da","420d97fa815e4ce9bd089c98f73aaef2","f89cd8747d704368bc877d50f0fda5c8","b1f61d3d6d644b36ac0572a09958816e","26877ad630cd4f9ba301842abd1d2973","1a79b0164b55410bb18a6a8dc658918c","d2850993d11a45bdaea7329b64b759c9","4207aaa1b53a489ab2b34107e23f0874","0791d408e094449ca5a4370c519c0836","d808851c7f094e54b688e3e3b68f8603","dbc01585b8c44e50b339b2cd3c10e479","81a64ec31dd3455f8556613df67aba26","0b8aed76e05e416da733f0a3f1c31327","646de8f25fc746d0b6c627a037fc25c0","ae99c27c0fa9401f8c0ac73e52ec071a","90cb97dc525d4fe3a1660ece9195fdcf","ffd2c974c726451c82bdb903ff5c14fd","fb07515110dd4009bc073d5b37718c01","43a6662791b14b0ab62d31f3614d1e8c","0467ad5746b44002b0813c86a294bea2","db29b617954f472ab5498dd387d13c23","443df18c92e74d8cadd56608d5b33dee","10eb75dbd2494d14ac65f78f93334a4c","ab011bbc4e934fd685942de8460f52ab","36c38ea504aa408185a4b84bc964fd0c","ebdff72bff0d4230a74c0df729687faa","53f5b77fe3494101bde487ad078dbf1d","b8606cb14d4c4004b7f87bc9e56e041c","03730195c8814c7c9ef3172ae9c60f5a","3d87da30029d41dfb18e2771fd2bfda0","b2289f3a57a146659fe1c4a1c4a5f33c"]},"id":"LxkZXONWEEi3","executionInfo":{"status":"ok","timestamp":1650718954076,"user_tz":-480,"elapsed":2293383,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"}},"outputId":"4bb67f33-c86f-4c32-c819-c1fbe2134810"},"outputs":[{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:608: UserWarning: Checkpoint directory /content/drive/.shortcut-targets-by-id/196KRvyUlmY05-hxnRYhLqB8B34eCLUel/Deep Learning exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name      | Type        | Params\n","------------------------------------------\n","0 | model     | CustomModel | 12.9 K\n","1 | train_acc | Accuracy    | 0     \n","2 | val_acc   | Accuracy    | 0     \n","3 | test_acc  | Accuracy    | 0     \n","------------------------------------------\n","12.9 K    Trainable params\n","0         Non-trainable params\n","12.9 K    Total params\n","0.051     Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b839ab825d4f4579aec421db000dd1ed"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4bbbc5064c346fda8bffd0500b5fb10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d808851c7f094e54b688e3e3b68f8603"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db29b617954f472ab5498dd387d13c23"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"]}],"source":["trainer = pl.Trainer(devices=\"auto\", accelerator=\"auto\", callbacks=callbacks, max_epochs=epochs, check_val_every_n_epoch=1)\n","trainer.fit(model, train_loader, val_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ihtc2GjBOmEb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650718959109,"user_tz":-480,"elapsed":529,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"}},"outputId":"8f896374-7a12-4eea-c5b5-4b531f2b79ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/196KRvyUlmY05-hxnRYhLqB8B34eCLUel/Deep Learning/04-23_11-54-10_epoch=0_val_loss=1.83.ckpt\n"]}],"source":["print(modelckpt_cb.best_model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urYQiD5pLCo-"},"outputs":[],"source":["# Manual saving\n","torch.save(model.model.state_dict(), model_name)  # Can replace with model_name"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243,"referenced_widgets":["017bc451d6ae46bab9f56aab3f0b0d68","fcb114fda5114bb1b11ae1ff11e5bed4","a23c4413ef034404b50c32b4027496cb","3e49a420a35a45cf91485d97b225b7ca","8ecd015cfc6c4559a85793fa1de02c90","30c234e9ed3c436a83d73e56b9063fc0","d8aadafd068a4f04a73ff6eaf180531d","ea5568d6e3c649c6893518100348c584","b061b844698f45679b517b65044ce716","255e13ade0c74d71bd70a21e6e363671","36c8914e8696461dbad707b11bddb9b7"]},"executionInfo":{"elapsed":129633,"status":"ok","timestamp":1650719308155,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"wEmXebbRJmbQ","outputId":"a7bb1735-7c11-46da-a771-0794be01b7d9"},"outputs":[{"output_type":"stream","name":"stderr","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Testing: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"017bc451d6ae46bab9f56aab3f0b0d68"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n","       Test metric             DataLoader 0\n","────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n","        test_acc            0.1679999977350235\n","        test_loss           2.1765480041503906\n","────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'test_acc': 0.1679999977350235, 'test_loss': 2.1765480041503906}]"]},"metadata":{},"execution_count":28}],"source":["trainer.test(model, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"3VYC9QjMI69z"},"source":["\n","We are doing data augmentation for test set also\n","\n","--------\n","\n","Model loading and testing\n","- saving and running from the same model\n","- Test dataloader should not perform data augmentation\n","\n","Printing of sample\n","- print out what is wrong\n","- sample output\n","- spectrogram print out\n","- confusion matrix\n"]},{"cell_type":"markdown","metadata":{"id":"EUabvNFZFwzf"},"source":["# Notes\n","> Function graveyard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2EUrOZ0N9d6u"},"outputs":[],"source":["# Feed this function into DataLoader when dealing with variable sized input \n","# with batch size > 1\n","# https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch\n","\n","def collate_fn(data):\n","    \"\"\"\n","       data: is a list of tuples with (example, label, length)\n","             where 'example' is a tensor of arbitrary shape\n","             and label/length are scalars\n","    \"\"\"\n","    print(data)\n","    signal_list, label_list = zip(*data)\n","\n","    return nn.utils.rnn.pad_sequence(signal_list), label_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ybbQ_2DqJNU5"},"outputs":[],"source":["import time\n","\n","for x, y in train_loader:\n","    asdf = x\n","    break\n","\n","iterations = 10000\n","\n","start = time.time()\n","for i in range(iterations):\n","    asdf.to(device)\n","    model.training_step(asdf)\n","\n","end = time.time()\n","\n","\n","print(f\"{iterations} iterations takes {(end - start):0.3f}s\")\n","print(f\"1 iteration takes {(end - start)/iterations * 1000:0.3f}ms\")\n","print(f\"{iterations / (end - start):.2f}it/s\")\n","\n","\n","# In batch size of 2,\n","# In the pipeline on CPU, it's 3.08it/s => 0.324675325s to load 1 batch\n","# inference only takes 0.202ms..."]},{"cell_type":"markdown","metadata":{"id":"EJwr-hOpKkQC"},"source":["With GPU, batch_size 2 \n","\n","At 16 workers, it is going at 9.25it/s\n","\n","At 32 workers, it is going at 16it/s"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qMXeqIA4Kwds"},"outputs":[],"source":["!cat /proc/cpuinfo"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"JunKaiCNN_tcn_v1","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b839ab825d4f4579aec421db000dd1ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be9c1e593bd34a62933c586912343573","IPY_MODEL_50fd3a076ca54a46ab255798a998cad9","IPY_MODEL_22a13dd545074b64b7b17c419e762c34"],"layout":"IPY_MODEL_c57ad4825fb845d0bf5e7575e0206a05"}},"be9c1e593bd34a62933c586912343573":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62eaa32e58734703b2a505f8c941635e","placeholder":"​","style":"IPY_MODEL_e48d3d93b4284997b341e0dbbf7453b4","value":"Sanity Checking DataLoader 0: 100%"}},"50fd3a076ca54a46ab255798a998cad9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7956156adfd4a9bb0892423117cdc37","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0452d9a90ae4bb8844b84b7d5a1c1d9","value":1}},"22a13dd545074b64b7b17c419e762c34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ac39a2e44cc46d196344658170996cb","placeholder":"​","style":"IPY_MODEL_908e808c239646a0a4d492e007c0bb04","value":" 2/2 [00:00&lt;00:00,  4.43it/s]"}},"c57ad4825fb845d0bf5e7575e0206a05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"62eaa32e58734703b2a505f8c941635e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e48d3d93b4284997b341e0dbbf7453b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7956156adfd4a9bb0892423117cdc37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0452d9a90ae4bb8844b84b7d5a1c1d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ac39a2e44cc46d196344658170996cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"908e808c239646a0a4d492e007c0bb04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4bbbc5064c346fda8bffd0500b5fb10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_163d9da531934d3eb1f20d64d77edb29","IPY_MODEL_35fdd2fe7e8b4a118d270e668f0165da","IPY_MODEL_420d97fa815e4ce9bd089c98f73aaef2"],"layout":"IPY_MODEL_f89cd8747d704368bc877d50f0fda5c8"}},"163d9da531934d3eb1f20d64d77edb29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1f61d3d6d644b36ac0572a09958816e","placeholder":"​","style":"IPY_MODEL_26877ad630cd4f9ba301842abd1d2973","value":"Epoch 2:  45%"}},"35fdd2fe7e8b4a118d270e668f0165da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a79b0164b55410bb18a6a8dc658918c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2850993d11a45bdaea7329b64b759c9","value":1}},"420d97fa815e4ce9bd089c98f73aaef2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4207aaa1b53a489ab2b34107e23f0874","placeholder":"​","style":"IPY_MODEL_0791d408e094449ca5a4370c519c0836","value":" 22060/49500 [38:12&lt;47:31,  9.62it/s, loss=1.7, v_num=1]"}},"f89cd8747d704368bc877d50f0fda5c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"b1f61d3d6d644b36ac0572a09958816e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26877ad630cd4f9ba301842abd1d2973":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a79b0164b55410bb18a6a8dc658918c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2850993d11a45bdaea7329b64b759c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4207aaa1b53a489ab2b34107e23f0874":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0791d408e094449ca5a4370c519c0836":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d808851c7f094e54b688e3e3b68f8603":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dbc01585b8c44e50b339b2cd3c10e479","IPY_MODEL_81a64ec31dd3455f8556613df67aba26","IPY_MODEL_0b8aed76e05e416da733f0a3f1c31327"],"layout":"IPY_MODEL_646de8f25fc746d0b6c627a037fc25c0"}},"dbc01585b8c44e50b339b2cd3c10e479":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae99c27c0fa9401f8c0ac73e52ec071a","placeholder":"​","style":"IPY_MODEL_90cb97dc525d4fe3a1660ece9195fdcf","value":"Validation DataLoader 0: 100%"}},"81a64ec31dd3455f8556613df67aba26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffd2c974c726451c82bdb903ff5c14fd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb07515110dd4009bc073d5b37718c01","value":1}},"0b8aed76e05e416da733f0a3f1c31327":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43a6662791b14b0ab62d31f3614d1e8c","placeholder":"​","style":"IPY_MODEL_0467ad5746b44002b0813c86a294bea2","value":" 4500/4500 [01:03&lt;00:00, 70.43it/s]"}},"646de8f25fc746d0b6c627a037fc25c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"ae99c27c0fa9401f8c0ac73e52ec071a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90cb97dc525d4fe3a1660ece9195fdcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffd2c974c726451c82bdb903ff5c14fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb07515110dd4009bc073d5b37718c01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43a6662791b14b0ab62d31f3614d1e8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0467ad5746b44002b0813c86a294bea2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db29b617954f472ab5498dd387d13c23":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_443df18c92e74d8cadd56608d5b33dee","IPY_MODEL_10eb75dbd2494d14ac65f78f93334a4c","IPY_MODEL_ab011bbc4e934fd685942de8460f52ab"],"layout":"IPY_MODEL_36c38ea504aa408185a4b84bc964fd0c"}},"443df18c92e74d8cadd56608d5b33dee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebdff72bff0d4230a74c0df729687faa","placeholder":"​","style":"IPY_MODEL_53f5b77fe3494101bde487ad078dbf1d","value":"Validation DataLoader 0: 100%"}},"10eb75dbd2494d14ac65f78f93334a4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8606cb14d4c4004b7f87bc9e56e041c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03730195c8814c7c9ef3172ae9c60f5a","value":1}},"ab011bbc4e934fd685942de8460f52ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d87da30029d41dfb18e2771fd2bfda0","placeholder":"​","style":"IPY_MODEL_b2289f3a57a146659fe1c4a1c4a5f33c","value":" 4500/4500 [01:02&lt;00:00, 71.94it/s]"}},"36c38ea504aa408185a4b84bc964fd0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"ebdff72bff0d4230a74c0df729687faa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53f5b77fe3494101bde487ad078dbf1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8606cb14d4c4004b7f87bc9e56e041c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03730195c8814c7c9ef3172ae9c60f5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d87da30029d41dfb18e2771fd2bfda0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2289f3a57a146659fe1c4a1c4a5f33c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"017bc451d6ae46bab9f56aab3f0b0d68":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fcb114fda5114bb1b11ae1ff11e5bed4","IPY_MODEL_a23c4413ef034404b50c32b4027496cb","IPY_MODEL_3e49a420a35a45cf91485d97b225b7ca"],"layout":"IPY_MODEL_8ecd015cfc6c4559a85793fa1de02c90"}},"fcb114fda5114bb1b11ae1ff11e5bed4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30c234e9ed3c436a83d73e56b9063fc0","placeholder":"​","style":"IPY_MODEL_d8aadafd068a4f04a73ff6eaf180531d","value":"Testing DataLoader 0: 100%"}},"a23c4413ef034404b50c32b4027496cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea5568d6e3c649c6893518100348c584","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b061b844698f45679b517b65044ce716","value":1}},"3e49a420a35a45cf91485d97b225b7ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_255e13ade0c74d71bd70a21e6e363671","placeholder":"​","style":"IPY_MODEL_36c8914e8696461dbad707b11bddb9b7","value":" 9000/9000 [02:09&lt;00:00, 69.73it/s]"}},"8ecd015cfc6c4559a85793fa1de02c90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"30c234e9ed3c436a83d73e56b9063fc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8aadafd068a4f04a73ff6eaf180531d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea5568d6e3c649c6893518100348c584":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b061b844698f45679b517b65044ce716":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"255e13ade0c74d71bd70a21e6e363671":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36c8914e8696461dbad707b11bddb9b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}