{"cells":[{"cell_type":"markdown","metadata":{"id":"PrqRK8C8Sz-m"},"source":["# Run this to use google drive as data source\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29198,"status":"ok","timestamp":1650719468680,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"-Z2URWqX8Wd6","outputId":"18173f65-c0e1-46ff-e782-dd59b8ae11e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# not ideal but can use this if you want to get some quick work done\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import time\n","from pathlib import Path\n","\n","kf_path = \"/content/drive/MyDrive/School/SUTD Term 6/Deep Learning/Deep Learning\"\n","jk_path = \"/content/drive/MyDrive/2. SUTD/SUTD Term 7/50.039 Deep Learning/Deep Learning Project/Mozilla Audio Dataset\"\n","qy_path = \"\"\n","riley_path = \"\"\n","se_path = \"\"\n","\n","# Change this your path to the gdrive\n","pwd = jk_path\n","model_ckpt_folder = \"JunKai_Models\"\n","\n","csv_file_path = Path(pwd, \"formatted.csv\")\n","root_audio_dir = Path(pwd, \"root_audio_dir/\")\n","audio_zip_path = Path(pwd, \"root_audio_dir.zip\")"]},{"cell_type":"markdown","metadata":{"id":"1JU1BVteunfP"},"source":["Takes up to 38GB available left\n","After running drops down to 50.86GB available left"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fB6aTROKptyK"},"outputs":[],"source":["!unzip -n -q \"$audio_zip_path\" -d ./\n","\n","root_audio_dir = \"root_audio_dir/\""]},{"cell_type":"markdown","metadata":{"id":"n7vNWPCDaRIs"},"source":["## OR Run this to use google colab as data source"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o3fawjGfOi7n"},"outputs":[],"source":["# !wget \"https://drive.google.com/uc?id=1MKzu-TfLKEygWOK5FpbVBsI8sKeB48DC&confirm=t\"\n","# !mv \"uc?id=1MKzu-TfLKEygWOK5FpbVBsI8sKeB48DC&confirm=t\" root_audio_dir.zip\n","\n","\n","# !wget \"https://drive.google.com/uc?export=download&id=1v0zhoVKLCSudS4XJFJHR3GWN28B5zdBB\"\n","# !mv \"uc?export=download&id=1v0zhoVKLCSudS4XJFJHR3GWN28B5zdBB\" formatted.csv\n","\n","\n","# csv_file_path = \"formatted.csv\"\n","# root_audio_dir = \"root_audio_dir/\""]},{"cell_type":"markdown","metadata":{"id":"faBReymMbmkO"},"source":["### Unzip and remove zip file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sq0kIKUOZU3P"},"outputs":[],"source":["# !unzip -q root_audio_dir.zip\n","# !rm root_audio_dir.zip\n","# !du -sh ./*"]},{"cell_type":"markdown","metadata":{"id":"tigPi8LPeMsX"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8561,"status":"ok","timestamp":1650719477237,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"Sp_izuI-cSp_","outputId":"165a79c9-3af9-4cc5-fa5f-7c8ac7e24622"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.6.1-py3-none-any.whl (582 kB)\n","\u001b[?25l\r\u001b[K     |▋                               | 10 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 39.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30 kB 40.8 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 61 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 71 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 81 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |█████                           | 92 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 102 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 112 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 122 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 133 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 143 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 153 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 163 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 174 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 184 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 194 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 204 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 215 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 225 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 235 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 245 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 256 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 266 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 276 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 286 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 296 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 307 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 317 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 327 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 337 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 348 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 358 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 368 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 378 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 389 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 399 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 409 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 419 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 430 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 440 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 450 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 460 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 471 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 481 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 491 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 501 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 512 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 522 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 532 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 542 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 552 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 563 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 573 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 582 kB 30.0 MB/s \n","\u001b[?25hCollecting torchinfo\n","  Downloading torchinfo-1.6.5-py3-none-any.whl (21 kB)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.1.1)\n","Collecting PyYAML>=5.4\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 66.1 MB/s \n","\u001b[?25hCollecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n","\u001b[K     |████████████████████████████████| 408 kB 71.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n","Collecting pyDeprecate<0.4.0,>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 73.4 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.10.0+cu111)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 64.5 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.8)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.44.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.6)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 72.7 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.9 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 75.0 MB/s \n","\u001b[?25hInstalling collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, PyYAML, torchinfo, pytorch-lightning\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.1 torchinfo-1.6.5 torchmetrics-0.8.0 yarl-1.7.2\n"]}],"source":["!pip install pytorch-lightning torchinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34rUKUc8eQ-M"},"outputs":[],"source":["import os\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchaudio\n","import torchaudio.transforms as T\n","import torch.utils.data as data\n","import pytorch_lightning as pl\n","\n","from torchinfo import summary"]},{"cell_type":"markdown","metadata":{"id":"LcLe9y1pDbVc"},"source":["# Creating Dataset to be fed into DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EGiOdcck8kH0"},"outputs":[],"source":["class CommonVoicesDataset(data.Dataset):\n","    # Some definitions:\n","    #   aud = (signal, sample_rate)\n","    #   sr = sample_rate\n","\n","    label_to_index = {i_val: i_in \n","                      for i_in, i_val in enumerate([\"teens\", \"twenties\",\n","                                                    \"thirties\", \"fourties\", \n","                                                    \"fifties\", \"sixties\"])}\n","\n","    def __init__(self, annotations_file, audio_dir, sample_rate, preprocessor):\n","        # preprocessor takes in aud and returns signal\n","\n","        self.annotations = pd.read_csv(annotations_file)\n","        if len(self.annotations.columns)> 2:\n","          columns_to_remove = []\n","          for col in self.annotations.columns:\n","            if not col in ['path','age']:\n","              columns_to_remove.append(col)\n","          self.annotations = self.annotations.drop(columns_to_remove, axis=1)\n","        self.audio_dir = audio_dir\n","        self.sample_rate = sample_rate\n","        self.resamplers = {}\n","        self.preprocessor = preprocessor\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        audio_sample_path = self._get_audio_sample_path(index)\n","        label = self._get_label(index)\n","        index = CommonVoicesDataset.label_to_index[label]  # Get index instead\n","        aud = torchaudio.load(audio_sample_path)\n","\n","        # resample to 48000 if different sample rate\n","        aud = self._resample(aud)\n","\n","        # Preprocessing step here\n","        signal = self.preprocessor(aud)\n","\n","        return signal, index\n","\n","    def _get_audio_sample_path(self, index):\n","        path = self.annotations.iloc[index,0]    \n","        final = os.path.join(self.audio_dir, path)\n","        return final\n","\n","    def _resample(self, aud, new_sr=None):\n","        if new_sr is None: new_sr = self.sample_rate\n","        signal, sr = aud\n","        if sr != new_sr:\n","            if not sr in self.resamplers:\n","                # Cache of resampling functions\n","                self.resamplers[sr] = T.Resample(sr, new_sr, dtype=signal.dtype)\n","            signal = self.resamplers[sr](signal)\n","        return signal, new_sr\n","\n","    def _get_label(self, index):\n","        return self.annotations.iloc[index,1]"]},{"cell_type":"markdown","metadata":{"id":"qa5-A39G1ehk"},"source":["# Audio preprocessing & mel spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DoFuJgyMP_X4"},"outputs":[],"source":["#Output: tensor\n","import matplotlib.pyplot as plt\n","import math\n","import random\n","import torch\n","import torchaudio\n","from torchaudio import transforms\n","\n","class AudioUtil():\n","    @staticmethod\n","    def open(audio_file):\n","        #load audio file\n","        signal, sample_rate = torchaudio.load(audio_file)\n","        return signal, sample_rate\n","\n","    @staticmethod\n","    def standardize_channel(aud):\n","        #to standardize the audio files to 1 channel (in case some have 2)\n","        signal, sample_rate = aud\n","\n","        if signal.shape[0] > 1:\n","          signal = torch.mean(signal, dim=0, keepdim=True)\n","\n","        return signal, sample_rate\n","\n","    @staticmethod\n","    def resampling(aud, target_sr):\n","      signal, sample_rate = aud\n","\n","      if sample_rate == target_sr:\n","        return aud\n","\n","      else:\n","        channel = signal.shape[0]\n","        resampled = torchaudio.transforms.Resample(sample_rate, target_sr)(signal[:1,:])\n","\n","        return resampled, target_sr\n","\n","\n","    @staticmethod\n","    def standardize_duration(aud, max_time):\n","        #standardize all audio files to the same length by either extending duration with silence or truncating it\n","        signal, sample_rate = aud\n","        num_of_rows, signal_length = signal.shape\n","        max_length = sample_rate//1000 * max_time\n","\n","        if (signal_length > max_length):\n","            #truncate signal to given length\n","            signal = signal[:, :max_length]\n","\n","        elif (signal_length < max_length):\n","            #length of padding to add\n","            padding_len = max_length - signal_length\n","\n","            #pad with 0s\n","            padding = torch.zeros(num_of_rows, padding_len)\n","\n","            signal = torch.cat((signal, padding), 1)\n","\n","        return signal, sample_rate\n","\n","    @staticmethod\n","    def time_shift(aud, shift_limit):\n","        #data augmentation on raw audio by time shifting to left/right by a random amount\n","        signal, sample_rate = aud\n","        _, signal_length = signal.shape\n","        amount_to_shift = int(random.random() * shift_limit * signal_length)\n","\n","        return signal.roll(amount_to_shift), sample_rate\n","\n","    @staticmethod\n","    def spectro_gram(aud, n_mels=64, n_fft = 1024, hop_len=None):\n","        #convert augmented audio to a mel spectrogram\n","        signal, sample_rate = aud\n","        top_db = 100\n","\n","        # Resultant length is sample_rate * seconds / (n_fft//2 - 1)\n","        spec = transforms.MelSpectrogram(sample_rate, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(signal)\n","\n","        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n","        return spec\n","\n","    @staticmethod\n","    def mel_spectrogram_augment(spec, max_mask=0.1, n_freq_masks=1, n_time_masks=1):\n","        #another round of augmentation, on mel spectrogram rather than raw data\n","        #frequency mask and time mask\n","        _, n_mels, n_steps = spec.shape\n","        mask_value = spec.mean()\n","        aug_spec = spec\n","\n","        #freq_mask_param: max possible time of the mask\n","        freq_mask_param = max_mask * n_mels\n","        for _ in range (n_freq_masks):\n","            aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n","\n","        #time_mask_param: max possible time of the mask\n","        time_mask_param = max_mask * n_steps\n","        for _ in range (n_time_masks):\n","            aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n","\n","        return aug_spec\n","\n","def example_spec_from_aud(audio_path):\n","    # Sample preprocessing pipeline\n","    aud = AudioUtil.open(audio_path)\n","    #reaud = AudioUtil.resampling(aud, 8000) #change the number to the sampling rate you want, here is 8khz\n","    mono = AudioUtil.standardize_channel(aud)\n","    fixed_duration = AudioUtil.standardize_duration(mono, 5000) #duration = 5s\n","    shift_aud = AudioUtil.time_shift(fixed_duration, 0.4) #40%\n","    spectrogram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n","    #n_mels = 64 because that is the normal speaking vocal range\n","    aug_sgram = AudioUtil.mel_spectrogram_augment(spectrogram, max_mask=0.1, n_freq_masks=2, n_time_masks=2)\n","    return aug_sgram\n","\n","\n","#######################################\n","###     preprocessing functions     ###\n","#######################################\n","\n","def raw_from_aud(aud):\n","    # Takes in raw aud, outputs preprocessed raw signal\n","    # Edit this to tune preprocessing\n","    \n","    new_aud = AudioUtil.resampling(aud, 8000) #change the number to the sampling rate you want, here is 8khz\n","    signal, sr = AudioUtil.standardize_channel(new_aud)\n","    # signal, sr = AudioUtil.standardize_duration(new_aud, 5000) #duration = 5s\n","\n","    return signal\n","\n","def spec_from_aud(aud):\n","    # Takes in raw aud, outputs preprocessed mel spectrogram\n","    # Edit this to tune preprocessing\n","\n","    new_aud = AudioUtil.standardize_channel(aud)\n","    new_aud = AudioUtil.standardize_duration(new_aud, 5460) #duration = 5.46s to get mel output length of 512\n","    new_aud = AudioUtil.time_shift(new_aud, 0.4) #40%\n","    spectrogram = AudioUtil.spectro_gram(new_aud, n_mels=64, n_fft=1024, hop_len=None)\n","    #n_mels = 64 because that is the normal speaking vocal range\n","    spectrogram = AudioUtil.mel_spectrogram_augment(spectrogram, max_mask=0.1, n_freq_masks=2, n_time_masks=2)\n","\n","    return spectrogram\n","\n","def print_spectrogram(tensor_input):\n","  #time vs amplitude\n","  two_d_spec = tensor_input[0]\n","  return plt.imshow(two_d_spec.permute(0,1))\n","\n","# output1 = example_spec_from_aud(\"/content/common_voice_en_1075485.mp3\")\n","# print (output1)\n","# print_spectrogram(output1)\n","# #print (output1.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"84zXhG71Djw-"},"source":["# Viewing dataset and Obtaining Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUS8sLrcawQt"},"outputs":[],"source":["##############################\n","###  Parameters to change  ###\n","##############################\n","\n","# Put your preprocessing functions here\n","PREPROCESSOR = raw_from_aud\n","# PREPROCESSOR = spec_from_aud\n","\n","BATCH_SIZE = 1  # Default 64\n","# If we were to have variable input length, keep batch_size at 1 or implement collate_fn()\n","\n","# This cuts the dataset down to have faster iterations during prototyping\n","REDUCED_DATASET = True\n","\n","num_workers = 4\n","# Need to experiment in this parameter.\n","# Colab gives 2 CPU cores."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":795,"status":"ok","timestamp":1650721491578,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"hTw-QkV1Cg-i","outputId":"25497d8a-62ff-4508-ed43-6aea1c2f8dfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["there are 450000 samples in the dataset\n","\n","the signal for the 300,000th dataset is:\n","\t tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -4.2633e-07,\n","         -1.4568e-07,  2.2841e-07]])\n","the label for the 300,000th dataset is:\n","\t 4 \n","\n","train_loader size:  45000\n","val_loader size:    4500\n","test_loader size:   9000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}],"source":["ANNOTATIONS_FILE = csv_file_path\n","AUDIO_DIRECTORY = root_audio_dir\n","SAMPLE_RATE = 48000\n","\n","cvd = CommonVoicesDataset(ANNOTATIONS_FILE, AUDIO_DIRECTORY, SAMPLE_RATE, PREPROCESSOR)\n","cvd_num_samples = len(cvd)\n","\n","print(f'there are {cvd_num_samples} samples in the dataset\\n')\n","\n","signal, label = cvd[299999]\n","print(\"the signal for the 300,000th dataset is:\\n\\t\",signal)\n","print(\"the label for the 300,000th dataset is:\\n\\t\",label,\"\\n\")\n","\n","if REDUCED_DATASET:\n","    # 10% for train_set, 1% for val, 2% for test\n","    train_set, val_set, test_set, _ = data.random_split(cvd, [int(cvd_num_samples * i) for i in (0.1, 0.01, 0.02, 0.87)])\n","else:\n","    # 80 - 20 split for train-test and then train-val\n","    train_set, val_set, test_set = data.random_split(cvd, [int(cvd_num_samples * i) for i in (0.64, 0.16, 0.20)])\n","\n","# checking if all rows are present\n","# for i in cvd:\n","#   if i == None:\n","#     print(\"error\")\n","#   pass\n","\n","train_loader = data.DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=num_workers)\n","val_loader = data.DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=num_workers)\n","test_loader = data.DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=num_workers)\n","\n","print(f\"train_loader size:  {len(train_loader.dataset)}\")\n","print(f\"val_loader size:    {len(val_loader.dataset)}\")\n","print(f\"test_loader size:   {len(test_loader.dataset)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":998,"status":"ok","timestamp":1650721492565,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"e3a3gF9FJi38","outputId":"805194ea-6976-4472-89d7-86cb28b8cd40"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.5937e-05,\n","          -6.1353e-05, -6.3669e-05]]])\n","torch.Size([1, 1, 51840])\n","\n","tensor([5])\n"]}],"source":["for a, b in train_loader:\n","    input_shape = a.shape\n","    print(a)\n","    print(input_shape)\n","    print()\n","    print(b)\n","    # print_spectrogram(a[0])\n","    # print_spectrogram(a[1])\n","    break\n","\n","# The result is batched"]},{"cell_type":"markdown","metadata":{"id":"YkmRG51QU-SG"},"source":["# Model functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61,"status":"ok","timestamp":1650721492566,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"TTeceVeLxyNz","outputId":"a5ce3bdd-9a92-47c1-cbce-88715b7e9b3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available: True\n"]}],"source":["# Load cuda, define device for torch\n","use_cuda = True\n","print(\"CUDA is available:\", torch.cuda.is_available())\n","device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"kiOCJ6xwYAz5"},"source":["## Standard parameters\n","- Loss function\n","- Optimizer\n","- training parameters\n","\n","Edit if needed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jBAsufOAXj4E"},"outputs":[],"source":["loss_function = F.nll_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6JnU7APEVNWs"},"outputs":[],"source":["optimizer = torch.optim.Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58,"status":"ok","timestamp":1650721492572,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"H734oD33X1vG","outputId":"72abae10-47e9-4c9b-eedf-27b0be01c7c3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f18300849f0>"]},"metadata":{},"execution_count":47}],"source":["# Define training parameters\n","learning_rate = 0.001\n","epochs = 50\n","torch.manual_seed(28)"]},{"cell_type":"markdown","metadata":{"id":"wlFu63MhVlfW"},"source":["## Model definition\n","\n","\n","- [x] Normalisation after pooling\n","- [ ] Standard (kernel_size=3) temporal convolution\n","- [x] relu after convolution\n","- [ ] Short cut connection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8BRee32EViH6"},"outputs":[],"source":["############################\n","### Edit your model here ###\n","############################\n","\n","# Basic CNN implementation for Mels spectrogram\n","class CustomModel(nn.Module):\n","\n","    def __init__(self, num_classes=6, any_other_params_you_need=None):\n","        super().__init__()\n","        self.num_classes = num_classes\n","\n","        # Define your layers here:\n","        self.conv1_1 = nn.Conv1d(1, 8, 2, padding=\"same\")\n","        self.conv1_2 = nn.Conv1d(8, 8, 2, dilation=2, padding=\"same\")\n","        self.bn1 = nn.BatchNorm1d(8)\n","        self.conv1_3 = nn.Conv1d(8, 16, 2, dilation=4, padding=\"same\")\n","        self.conv1_4 = nn.Conv1d(16, 16, 2, dilation=8, padding=\"same\")\n","        self.bn2 = nn.BatchNorm1d(16)\n","        self.conv1_5 = nn.Conv1d(16, 32, 2, dilation=16, padding=\"same\")\n","        self.conv1_6 = nn.Conv1d(32, 32, 2, dilation=32, padding=\"same\")\n","        self.bn3 = nn.BatchNorm1d(32)\n","        self.conv1_7 = nn.Conv1d(32, 64, 2, dilation=64, padding=\"same\")\n","        self.conv1_8 = nn.Conv1d(64, 64, 2, dilation=128, padding=\"same\")\n","        self.bn4 = nn.BatchNorm1d(64)\n","\n","        self.lstm1 = nn.LSTM(64, 128)\n","\n","        self.fc1 = nn.Linear(128, self.num_classes)\n","\n","        self.poolingx2 = lambda x: F.max_pool1d(x, 2, stride=2)\n","\n","    def forward(self, inputs):\n","\n","        # print(\"input\", inputs.shape)\n","\n","        x1 = F.relu(self.conv1_1(inputs))\n","        x1 = self.poolingx2(x1)\n","        x1 = F.relu(self.conv1_2(x1))\n","        x1 = self.poolingx2(x1)\n","        x1 = self.bn1(x1)\n","        # print(\"x1\", x1.shape)\n","\n","        x2 = F.relu(self.conv1_3(x1))\n","        x2 = self.poolingx2(x2)\n","        x2 = F.relu(self.conv1_4(x2))\n","        x2 = self.poolingx2(x2)\n","        x2 = self.bn2(x2)\n","\n","        # print(\"x2\", x2.shape)\n","\n","        x3 = F.relu(self.conv1_5(x2))\n","        x3 = self.poolingx2(x3)\n","        x3 = F.relu(self.conv1_6(x3))\n","        x3 = self.poolingx2(x3)\n","        x3 = self.bn3(x3)\n","\n","        # print(\"x3\", x3.shape)\n","\n","        x4 = F.relu(self.conv1_7(x3))\n","        x4 = self.poolingx2(x4)\n","        x4 = F.relu(self.conv1_8(x4))\n","        x4 = self.poolingx2(x4)\n","        x4 = self.bn4(x4)\n","\n","        # print(\"x4\", x4.shape)\n","\n","        x5 = torch.transpose(x4, 1, 2)\n","        x5, _ = self.lstm1(x5)\n","        x5 = x5[:,-1, :]  # Get the last output\n","\n","        # print(\"x5\", x5.shape)\n","        \n","        x6 = self.fc1(x5)\n","\n","        # print(\"x6\", x6.shape)\n","\n","        # x = torch.cat([x1, x12], dim=1)\n","\n","        return F.log_softmax(x6, dim=1)\n"]},{"cell_type":"markdown","metadata":{"id":"z83VEs0WX8BC"},"source":["# Train model"]},{"cell_type":"markdown","source":["### Initialise trainer"],"metadata":{"id":"2fPtcmLxyVhx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhGr2ZRoPo13"},"outputs":[],"source":["import pytorch_lightning as pl\n","import torchmetrics\n","\n","class LightningModel(pl.LightningModule):\n","    def __init__(self, model, learning_rate=1e-3, loss_function=F.nll_loss, optimizer=torch.optim.Adam, weight_decay=1e-6):\n","        super().__init__()\n","        self.learning_rate = learning_rate\n","        self.loss_function = loss_function\n","        # Weight decay for L2 regularization\n","        self.optimizer = optimizer(model.parameters(), lr=self.learning_rate, weight_decay=weight_decay)\n","        self.model = model\n","        \n","        self.train_acc = torchmetrics.Accuracy()\n","        self.val_acc = torchmetrics.Accuracy()\n","        self.test_acc = torchmetrics.Accuracy()\n","\n","    def forward(self, x):\n","        # in lightning, forward defines the prediction/inference actions\n","        output = self.model(x)\n","        return output\n","\n","    def training_step(self, batch, batch_idx):\n","        # training_step defined the train loop.\n","        # It is independent of forward\n","        x, y = batch\n","        output = self(x)  # Call self.forward function\n","        loss = self.loss_function(output, y)\n","        self.train_acc(output, y)\n","        # Logging to TensorBoard by default\n","        self.log(\"train_loss\", loss, on_epoch=True)\n","        self.log(\"train_acc\", self.train_acc, on_epoch=True)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        # training_step defined the train loop.\n","        # It is independent of forward\n","        x, y = batch\n","        output = self(x)  # Call self.forward function\n","        loss = self.loss_function(output, y)\n","        self.val_acc(output, y)\n","        # Logging to TensorBoard by default\n","        self.log(\"val_loss\", loss, on_epoch=True)\n","        self.log(\"val_acc\", self.val_acc, on_epoch=True)\n","        return loss\n","\n","    def test_step(self, batch, batch_idx):\n","        # training_step defined the train loop.\n","        # It is independent of forward\n","        x, y = batch\n","        output = self(x)  # Call self.forward function\n","        loss = self.loss_function(output, y)\n","        self.test_acc(output, y)\n","        # Logging to TensorBoard by default\n","        self.log(\"test_loss\", loss, on_epoch=True)\n","        self.log(\"test_acc\", self.test_acc, on_epoch=True)\n","        return loss\n","\n","    def configure_optimizers(self):\n","        return self.optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1650721598600,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"AUR9A9RcM3tz","outputId":"00b70c3e-ce8d-48a9-8dc5-5a61f2217a8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["model name 04-23_13-46-38\n","model will be saved at: /content/drive/MyDrive/2. SUTD/SUTD Term 7/50.039 Deep Learning/Deep Learning Project/Mozilla Audio Dataset/JunKai_Models/04-23_13-46-38\n","LightningModel(\n","  (model): CustomModel(\n","    (conv1_1): Conv1d(1, 8, kernel_size=(2,), stride=(1,), padding=same)\n","    (conv1_2): Conv1d(8, 8, kernel_size=(2,), stride=(1,), padding=same, dilation=(2,))\n","    (bn1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv1_3): Conv1d(8, 16, kernel_size=(2,), stride=(1,), padding=same, dilation=(4,))\n","    (conv1_4): Conv1d(16, 16, kernel_size=(2,), stride=(1,), padding=same, dilation=(8,))\n","    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv1_5): Conv1d(16, 32, kernel_size=(2,), stride=(1,), padding=same, dilation=(16,))\n","    (conv1_6): Conv1d(32, 32, kernel_size=(2,), stride=(1,), padding=same, dilation=(32,))\n","    (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv1_7): Conv1d(32, 64, kernel_size=(2,), stride=(1,), padding=same, dilation=(64,))\n","    (conv1_8): Conv1d(64, 64, kernel_size=(2,), stride=(1,), padding=same, dilation=(128,))\n","    (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (lstm1): LSTM(64, 128)\n","    (fc1): Linear(in_features=128, out_features=6, bias=True)\n","  )\n","  (train_acc): Accuracy()\n","  (val_acc): Accuracy()\n","  (test_acc): Accuracy()\n",")\n"]},{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","LightningModel                           --                        --\n","├─CustomModel: 1-1                       [1, 6]                    --\n","│    └─Conv1d: 2-1                       [1, 8, 51840]             24\n","│    └─Conv1d: 2-2                       [1, 8, 25920]             136\n","│    └─BatchNorm1d: 2-3                  [1, 8, 12960]             16\n","│    └─Conv1d: 2-4                       [1, 16, 12960]            272\n","│    └─Conv1d: 2-5                       [1, 16, 6480]             528\n","│    └─BatchNorm1d: 2-6                  [1, 16, 3240]             32\n","│    └─Conv1d: 2-7                       [1, 32, 3240]             1,056\n","│    └─Conv1d: 2-8                       [1, 32, 1620]             2,080\n","│    └─BatchNorm1d: 2-9                  [1, 32, 810]              64\n","│    └─Conv1d: 2-10                      [1, 64, 810]              4,160\n","│    └─Conv1d: 2-11                      [1, 64, 405]              8,256\n","│    └─BatchNorm1d: 2-12                 [1, 64, 202]              128\n","│    └─LSTM: 2-13                        [1, 202, 128]             99,328\n","│    └─Linear: 2-14                      [1, 6]                    774\n","├─Accuracy: 1-2                          --                        --\n","├─Accuracy: 1-3                          --                        --\n","├─Accuracy: 1-4                          --                        --\n","==========================================================================================\n","Total params: 116,854\n","Trainable params: 116,854\n","Non-trainable params: 0\n","Total mult-adds (M): 45.29\n","==========================================================================================\n","Input size (MB): 0.21\n","Forward/backward pass size (MB): 11.09\n","Params size (MB): 0.47\n","Estimated Total Size (MB): 11.77\n","=========================================================================================="]},"metadata":{},"execution_count":56}],"source":["############################\n","###  Specify model name  ###\n","############################\n","\n","# If there is a model with the same name, training will continue on from that model\n","model_name = \"\"\n","\n","\n","if model_name == \"\":\n","    model_name = time.strftime(\"%m-%d_%H-%M-%S\", time.gmtime())\n","    model = LightningModel(CustomModel(), learning_rate=learning_rate, loss_function=loss_function, optimizer=optimizer)\n","else:\n","    # Load state dict from the disk (make sure it is the same name as above)\n","    state_dict = torch.load(model_name)\n","\n","    # Create a new model and load the state\n","    model = LightningModel(CustomModel(), learning_rate=learning_rate, loss_function=loss_function, optimizer=optimizer)\n","    model.load_state_dict(state_dict)\n","\n","model_save_path = Path(pwd, model_ckpt_folder, model_name)\n","\n","print(\"model name\", model_name)\n","print(\"model will be saved at:\", model_save_path)\n","print(model)\n","\n","summary(model, input_size=input_shape)  # This function will throw error when model is ill-defined"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snfuCmk8enWG"},"outputs":[],"source":["from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n","\n","# https://pytorch-lightning.readthedocs.io/en/stable/common/early_stopping.html\n","earlystopping_cb = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=4)\n","\n","# https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.ModelCheckpoint.html\n","# Saves file like: <model_save_path>/<modelname>_2_0.32.ckpt\n","modelckpt_cb = ModelCheckpoint(monitor=\"val_loss\", dirpath=model_save_path, filename=model_name+\"_{epoch}_{val_loss:.2f}\")\n","\n","callbacks = [earlystopping_cb, modelckpt_cb] \n"]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"bnrWX0mVyazA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lxa1zvQQMrPU"},"outputs":[],"source":["# Launch tensorboard\n","\n","%reload_ext tensorboard\n","%tensorboard --logdir=lightning_logs/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451,"referenced_widgets":["733a64942b414c1698cda7aeb959eece","f343b2f0c82d41c9b39f429556cc643d","92ec5968a315433088e30dfc1f7ad44e","35fe4b11445e4107912033a1dda7c3b3","533d51c701614c8d9dcde47ca4a172f5","46701c4a6ff046bd9e4a80ee24eae63d","965b2c465eb74db6a97d6618c1828469","7d4a801936ad439e83c7ed14428aa24f","f7471eb48d854df5a8f413dbc9833bc2","d14239425ba44896b560b581c1a4fda3","6c2c05fb32ec490e9d0a00afbcb095aa","ca34671ef091492a8d602dd7537e4988","a2a93921e9124fc39edc41ee1b17e074","93a3f0374e0b413f84c7351e9d27282f","861d391bfaf34877959d1fba892142a8","22e6d55a5e2245b4839462f66263673e","734d221c90fe42a8a31aa864e2db121c","e46348f76cc941a9a9110c29c5f2064d","08d44373742d473ba24424139edbe775","947f88d151544d09958f86c6a54e63c8","d399a1203ca34289826e140ac80243a0","89c93044847742e18e9f29ea3dcc5269","998e17b2af7149db99b40bd262035fb8","61208911a1b04eb886603decb86af3d6","e25b9164f51b4c5ea650831f9c70b99d","6385156998d04e86b2a9171a36b4fee5","116759c2ddf54d9fa1b473ab0153f046","304129a22b0d4879b1c24594a9cbb56e","80227e57cb684e5b84d28a6c2f370736","edf080c6d6e7458a8a4e14ba19617812","9f2b4073804b4685ac74738cf24877b6","29e32596521f47b297aad7e4668c82bc","5c20609c443e42d39d886e4f121368fd"]},"id":"LxkZXONWEEi3","outputId":"7581b815-69e9-467d-9611-397bfcdcde9a","executionInfo":{"status":"ok","timestamp":1650723213483,"user_tz":-480,"elapsed":1600838,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","Missing logger folder: /content/lightning_logs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name      | Type        | Params\n","------------------------------------------\n","0 | model     | CustomModel | 116 K \n","1 | train_acc | Accuracy    | 0     \n","2 | val_acc   | Accuracy    | 0     \n","3 | test_acc  | Accuracy    | 0     \n","------------------------------------------\n","116 K     Trainable params\n","0         Non-trainable params\n","116 K     Total params\n","0.467     Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"733a64942b414c1698cda7aeb959eece"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca34671ef091492a8d602dd7537e4988"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validation: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"998e17b2af7149db99b40bd262035fb8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:724: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"]}],"source":["trainer = pl.Trainer(devices=\"auto\", accelerator=\"auto\", callbacks=callbacks, max_epochs=epochs, check_val_every_n_epoch=1)\n","trainer.fit(model, train_loader, val_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ihtc2GjBOmEb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650723217794,"user_tz":-480,"elapsed":395,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"}},"outputId":"f3bdefb9-e1dd-43d1-fa0e-c1b519063a44"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/196KRvyUlmY05-hxnRYhLqB8B34eCLUel/Deep Learning/JunKai_Models/04-23_13-46-38/04-23_13-46-38_epoch=0_val_loss=1.81.ckpt\n"]}],"source":["print(modelckpt_cb.best_model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urYQiD5pLCo-"},"outputs":[],"source":["# Manual saving\n","torch.save(trainer.model.state_dict(), \"/content/drive/.shortcut-targets-by-id/196KRvyUlmY05-hxnRYhLqB8B34eCLUel/Deep Learning/JunKai_Models/CNN_tcn_v2.pth\")  # Can replace with model_name"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":123895,"status":"ok","timestamp":1650723535851,"user":{"displayName":"Lo Jun Kai","userId":"06658869486867465477"},"user_tz":-480},"id":"wEmXebbRJmbQ","colab":{"base_uri":"https://localhost:8080/","height":243,"referenced_widgets":["39523b99eafc465da26ea4de75db0c33","cde1910dcb1f4985a63e0aa4485dc07e","28be79ed7f9349f9b9b3c1c4a58ea55d","fb33bbb92d5a48d1bad2044d6f1f9f2a","9a690fbcfb434aa08b995efc26825336","f5598e50cf864340a276092f882ade48","5a5a8c1fdaeb42fda4882cf4a75a98e4","dbcc3640be0c4b94911c56971f780220","f209ef842eb5417bb25c22ab5b1e2404","5776320a8dd24775b9e27b630baf9e62","4fb9fbf5a97e4749a2ec4ecb23bce247"]},"outputId":"0f684b1f-8b17-4cdd-c7a8-cccda5e96f5a"},"outputs":[{"output_type":"stream","name":"stderr","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"display_data","data":{"text/plain":["Testing: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39523b99eafc465da26ea4de75db0c33"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n","       Test metric             DataLoader 0\n","────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n","        test_acc            0.17299999296665192\n","        test_loss           1.8076070547103882\n","────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'test_acc': 0.17299999296665192, 'test_loss': 1.8076070547103882}]"]},"metadata":{},"execution_count":62}],"source":["trainer.test(model, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"3VYC9QjMI69z"},"source":["\n","We are doing data augmentation for test set also\n","\n","--------\n","\n","Model loading and testing\n","- saving and running from the same model\n","- Test dataloader should not perform data augmentation\n","\n","Printing of sample\n","- print out what is wrong\n","- sample output\n","- spectrogram print out\n","- confusion matrix\n"]},{"cell_type":"markdown","metadata":{"id":"EUabvNFZFwzf"},"source":["# Notes\n","> Function graveyard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2EUrOZ0N9d6u"},"outputs":[],"source":["# Feed this function into DataLoader when dealing with variable sized input \n","# with batch size > 1\n","# https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch\n","\n","def collate_fn(data):\n","    \"\"\"\n","       data: is a list of tuples with (example, label, length)\n","             where 'example' is a tensor of arbitrary shape\n","             and label/length are scalars\n","    \"\"\"\n","    print(data)\n","    signal_list, label_list = zip(*data)\n","\n","    return nn.utils.rnn.pad_sequence(signal_list), label_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ybbQ_2DqJNU5"},"outputs":[],"source":["import time\n","\n","for x, y in train_loader:\n","    asdf = x\n","    break\n","\n","iterations = 10000\n","\n","start = time.time()\n","for i in range(iterations):\n","    asdf.to(device)\n","    model.training_step(asdf)\n","\n","end = time.time()\n","\n","\n","print(f\"{iterations} iterations takes {(end - start):0.3f}s\")\n","print(f\"1 iteration takes {(end - start)/iterations * 1000:0.3f}ms\")\n","print(f\"{iterations / (end - start):.2f}it/s\")\n","\n","\n","# In batch size of 2,\n","# In the pipeline on CPU, it's 3.08it/s => 0.324675325s to load 1 batch\n","# inference only takes 0.202ms..."]},{"cell_type":"markdown","metadata":{"id":"EJwr-hOpKkQC"},"source":["With GPU, batch_size 2 \n","\n","At 16 workers, it is going at 9.25it/s\n","\n","At 32 workers, it is going at 16it/s"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qMXeqIA4Kwds"},"outputs":[],"source":["!cat /proc/cpuinfo"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"JunKaiCNN_tcn_v2","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"733a64942b414c1698cda7aeb959eece":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f343b2f0c82d41c9b39f429556cc643d","IPY_MODEL_92ec5968a315433088e30dfc1f7ad44e","IPY_MODEL_35fe4b11445e4107912033a1dda7c3b3"],"layout":"IPY_MODEL_533d51c701614c8d9dcde47ca4a172f5"}},"f343b2f0c82d41c9b39f429556cc643d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46701c4a6ff046bd9e4a80ee24eae63d","placeholder":"​","style":"IPY_MODEL_965b2c465eb74db6a97d6618c1828469","value":"Sanity Checking DataLoader 0: 100%"}},"92ec5968a315433088e30dfc1f7ad44e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d4a801936ad439e83c7ed14428aa24f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7471eb48d854df5a8f413dbc9833bc2","value":1}},"35fe4b11445e4107912033a1dda7c3b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d14239425ba44896b560b581c1a4fda3","placeholder":"​","style":"IPY_MODEL_6c2c05fb32ec490e9d0a00afbcb095aa","value":" 2/2 [00:00&lt;00:00,  4.82it/s]"}},"533d51c701614c8d9dcde47ca4a172f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"46701c4a6ff046bd9e4a80ee24eae63d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"965b2c465eb74db6a97d6618c1828469":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d4a801936ad439e83c7ed14428aa24f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7471eb48d854df5a8f413dbc9833bc2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d14239425ba44896b560b581c1a4fda3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c2c05fb32ec490e9d0a00afbcb095aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca34671ef091492a8d602dd7537e4988":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2a93921e9124fc39edc41ee1b17e074","IPY_MODEL_93a3f0374e0b413f84c7351e9d27282f","IPY_MODEL_861d391bfaf34877959d1fba892142a8"],"layout":"IPY_MODEL_22e6d55a5e2245b4839462f66263673e"}},"a2a93921e9124fc39edc41ee1b17e074":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_734d221c90fe42a8a31aa864e2db121c","placeholder":"​","style":"IPY_MODEL_e46348f76cc941a9a9110c29c5f2064d","value":"Epoch 1:  66%"}},"93a3f0374e0b413f84c7351e9d27282f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_08d44373742d473ba24424139edbe775","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_947f88d151544d09958f86c6a54e63c8","value":1}},"861d391bfaf34877959d1fba892142a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d399a1203ca34289826e140ac80243a0","placeholder":"​","style":"IPY_MODEL_89c93044847742e18e9f29ea3dcc5269","value":" 32440/49500 [26:39&lt;14:01, 20.28it/s, loss=1.92, v_num=0]"}},"22e6d55a5e2245b4839462f66263673e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"734d221c90fe42a8a31aa864e2db121c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e46348f76cc941a9a9110c29c5f2064d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08d44373742d473ba24424139edbe775":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"947f88d151544d09958f86c6a54e63c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d399a1203ca34289826e140ac80243a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89c93044847742e18e9f29ea3dcc5269":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"998e17b2af7149db99b40bd262035fb8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61208911a1b04eb886603decb86af3d6","IPY_MODEL_e25b9164f51b4c5ea650831f9c70b99d","IPY_MODEL_6385156998d04e86b2a9171a36b4fee5"],"layout":"IPY_MODEL_116759c2ddf54d9fa1b473ab0153f046"}},"61208911a1b04eb886603decb86af3d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_304129a22b0d4879b1c24594a9cbb56e","placeholder":"​","style":"IPY_MODEL_80227e57cb684e5b84d28a6c2f370736","value":"Validation DataLoader 0: 100%"}},"e25b9164f51b4c5ea650831f9c70b99d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_edf080c6d6e7458a8a4e14ba19617812","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f2b4073804b4685ac74738cf24877b6","value":1}},"6385156998d04e86b2a9171a36b4fee5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29e32596521f47b297aad7e4668c82bc","placeholder":"​","style":"IPY_MODEL_5c20609c443e42d39d886e4f121368fd","value":" 4500/4500 [00:59&lt;00:00, 75.33it/s]"}},"116759c2ddf54d9fa1b473ab0153f046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"304129a22b0d4879b1c24594a9cbb56e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80227e57cb684e5b84d28a6c2f370736":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edf080c6d6e7458a8a4e14ba19617812":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f2b4073804b4685ac74738cf24877b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29e32596521f47b297aad7e4668c82bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c20609c443e42d39d886e4f121368fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39523b99eafc465da26ea4de75db0c33":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cde1910dcb1f4985a63e0aa4485dc07e","IPY_MODEL_28be79ed7f9349f9b9b3c1c4a58ea55d","IPY_MODEL_fb33bbb92d5a48d1bad2044d6f1f9f2a"],"layout":"IPY_MODEL_9a690fbcfb434aa08b995efc26825336"}},"cde1910dcb1f4985a63e0aa4485dc07e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5598e50cf864340a276092f882ade48","placeholder":"​","style":"IPY_MODEL_5a5a8c1fdaeb42fda4882cf4a75a98e4","value":"Testing DataLoader 0: 100%"}},"28be79ed7f9349f9b9b3c1c4a58ea55d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbcc3640be0c4b94911c56971f780220","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f209ef842eb5417bb25c22ab5b1e2404","value":1}},"fb33bbb92d5a48d1bad2044d6f1f9f2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5776320a8dd24775b9e27b630baf9e62","placeholder":"​","style":"IPY_MODEL_4fb9fbf5a97e4749a2ec4ecb23bce247","value":" 9000/9000 [02:03&lt;00:00, 72.82it/s]"}},"9a690fbcfb434aa08b995efc26825336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"f5598e50cf864340a276092f882ade48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a5a8c1fdaeb42fda4882cf4a75a98e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbcc3640be0c4b94911c56971f780220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f209ef842eb5417bb25c22ab5b1e2404":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5776320a8dd24775b9e27b630baf9e62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fb9fbf5a97e4749a2ec4ecb23bce247":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}